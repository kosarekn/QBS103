#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       READ IN LIBRARIES
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(caret)
library(ggplot2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                     READ IN SCAT DATA
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Let's take a look at what our data look like
head(scat)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                     READ IN SCAT DATA
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
data(scat)
# Let's take a look at what our data look like
head(scat)
# Let's see how many observations and variables are in our example data
dim(scat)
# How many categories are in our classification?
factor(levels(scat$Species))
# Is there any missing data in our example data?
length(which(is.na(scat) == TRUE))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         DATA CLEANING
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# We will use KNN imputation, but there is also the option for tree bagging
preProcValues <- preProcess(scat, method=c("knnImpute","center", "scale" ))
cleanData <- predict (preProcValues, scat)
# Is there any missing data in our example data?
length(which(is.na(cleanData) == TRUE))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         DATA SPLITTING
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# We will set a seed so we end up with the same split
set.seed(3456)
# This code splits our data
trainIndex <- createDataPartition(cleanData$Species, p = 2/3, list = FALSE, times = 1)
# We assign the 2/3 of data to a training set variable
Train <- cleanData[ trainIndex,]
# We assign the remaining 1/3 of data to a testing set variable
Test <- cleanData[-trainIndex,]
# Let's take a look at the dimensions of our training and testing set to see if that all worked out ok
dim(Train)
dim(Test)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       INITAL MODEL FITTING
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# In this line of code we are indicating that we will be using the default parameters. In our next step this will change because we will be tuning some parameters.
fitControl <- trainControl(method = "none")
# We will set a seed so we end up with the same split
set.seed(825)
# Conduct model fitting
Fit1 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
# Other Methods: “pls” for PLS-DA, “svmLinear” for linear svm, “svmRadial”, “knn”, “glmnet” for elastic net
Fit1
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       K-FOLD CROSS VALIDATION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# k-fold cross validation
fitControl <- trainControl(method = "cv", number = 5)
# We will set a seed so we end up with the same split
set.seed(825)
# Conduct model fitting
Fit2 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit2
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                 REPEATED K-FOLD CROSS VALIDATION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# repeated k-fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 5,repeats = 10)
# We will set a seed so we end up with the same split
set.seed(825)
# Conduct model fitting
Fit3 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit3
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                 LEAVE-ONE-OUT CROSS VALIDATION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Leave one out cross validation
fitControl <- trainControl(method = "LOOCV")
# We will set a seed so we end up with the same split
set.seed(825)
# Conduct model fitting
Fit4 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit4
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         BOOTSTRAPPING
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Leave one out cross validation
fitControl <- trainControl(method = "boot", number = 100)
# We will set a seed so we end up with the same split
set.seed(825)
# Conduct model fitting
Fit5 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, verbose = FALSE)
Fit5
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         GRID SEARCH
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Note that this is the same as the bootstrapping!
fitControl <- trainControl(method = "boot", number = 100)
# We will set a seed so we end up with the same split
set.seed(825)
# NOTE: tuneLength = 5 here, this is the grid search!
Fit6 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl, tuneLength = 5, verbose = FALSE)
Fit6
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         CLASS IMBALANCE
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Note that this is the same as the bootstrapping, but here we add downsampling!
fitControl <- trainControl(method = "boot", number = 100 , sampling = "down")
# We will set a seed so we end up with the same split
set.seed(825)
# NOTE: tuneLength = 5 here
Fit7 <- train(Species ~ ., data = Train, method = "rf", trControl = fitControl,
tuneLength = 5, verbose = FALSE)
Fit7
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       FEATURE SELECTION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Select the most important variables
Imp <- varImp(Fit1, scale = FALSE)
# Make a plot of which variables are the most important
plot(Imp, top = 20)
# Select the top 15 most important variables
featSel<-which(Imp$importance$Overall>=15)
length(featSel)
# Subset the training set to contain only those variables
featDF<-Train[,featSel]
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       FEATURE SELECTION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This function generates a control object that can be used to specify the details of the feature selection algorithms used in this package
rctrl1 <- rfeControl(method = "cv", functions = caretFuncs, allowParallel = F)
trainCtl1<-trainControl(method = "cv", number=3, classProbs = TRUE, allowParallel = F)
# We will set a seed so we end up with the same split
set.seed(24)
# Run simple backward selection
Fit8 <- rfe(x=Train,y=Train$Species,
sizes = c(5,10,15,20,25,30,35,40,45,50,75,100),
method = "rf", trControl = trainCtl1, tuneLength = 10, rfeControl = rctrl1)
Fit8
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#               PREDICTIVE MODELING AND VALIDATION
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
preds<-predict(Fit3,Test)
confusionMatrix(preds,Test$Species,positive="coyote")
